{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging Bad Solutions: Module 1, Part 1\n",
    "\n",
    "From Midterm 2, Spring 2023 - One and Two-Point Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gt-cse-6040/bootcamp/blob/main/Module%201/Session%208/m1s8nb1_Data_Debugging_part1%20-%20Exercises.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the exams you may initially write solutions that do not pass the test cases. That's okay! You will need to debug your code to determine what is causing the issue(s) and then figure out to how fix them. So how can we get better at debugging? We practice!\n",
    "\n",
    "Below are three 1-point exercises and one 2-point exercise from the Spring 2023 Midterm 2. We have pre-written solutions for each exercise that are \"bad\" in one or more ways. Our solutions may contain one or more logic and/or syntax errors. Can you find and fix the issues in each exercise and pass all of the test cases?\n",
    "\n",
    "Right before each exercise test cell, there is a block of text explaining the variables available to you for debugging. You may use these to test your code and can print/display them as needed.\n",
    "\n",
    "**Exercise point breakdown:**\n",
    "\n",
    "- Exercise 1: **1** point\n",
    "- Exercise 5: **2** points\n",
    "- Exercise 6: **2** points\n",
    "- Exercise 7: **1** point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Background: Better Reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Goodreads](https://www.goodreads.com/) is a website devoted to curating user-generated book reviews. You'll do some elementary data-mining to uncover \"communities\" of users who like the same books. Such insights might help users find like-minded communities and generate better book recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cells to download the required files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import files\n",
    "!mkdir resources\n",
    "%cd resources\n",
    "\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/resources/demo_ex1.db\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/resources/demo_ex6.obj\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/resources/demo_ex7.db\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/resources/ex1-is_read.df\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/resources/ex1-is_reviewed.df\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/resources/goodreads.db\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/resources/tc_1\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/resources/tc_4\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/resources/tc_6\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/resources/tc_7\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/resources/ex1-rating.df\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/resources/ex1-user_id.df\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/resources/ex6-comms.df\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/resources/ex7-means.df\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/resources/ex7-sampler-input.df\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/resources/tc_5\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/resources/demo_ex5.df\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/resources/ex5.df\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/resources/requirements.txt\n",
    "\n",
    "%cd ..\n",
    "!mkdir tester_fw\n",
    "%cd tester_fw\n",
    "\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/tester_fw/__init__.py\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/tester_fw/test_utils.py\n",
    "!wget -nc https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%208/tester_fw/testers.py\n",
    "\n",
    "%cd ..\n",
    "\n",
    "!python -m pip install -r resources/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required Modules and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cells to configure your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Python modules\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3 as db\n",
    "import math\n",
    "import dill as pickle\n",
    "from pprint import pprint, pformat\n",
    "from tester_fw.db_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case it's helpful, here are the versions of Python and standard modules you are using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"* Python version: {}\".format(sys.version.replace('\\n', ' ')))\n",
    "print(f\"* Numpy version: {np.__version__}\")\n",
    "print(f\"* pandas version: {pd.__version__}\")\n",
    "print(f\"* sqlite3 version: {db.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connecting to the Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the Goodreads data is stored in a SQLite3 database. The code cell below opens a read-only connection to it named **`grdbconn`**.\n",
    "\n",
    "For now, don't worry about what's there. We will explain any tables you need in the exercises that use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goodreads database connection:\n",
    "# grdbconn = db.connect('file:resource/asnlib/publicdata/goodreads.db?mode=ro', uri=True)\n",
    "grdbconn = db.connect('file:resources/goodreads.db?mode=ro', uri=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ex. 1 (1 pt)**: `count_interactions_by`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background: Analyzing user-book interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Goodreads dataset includes **user-book interactions.** An \"user-book interaction\" means the user \"did something\" with the book on the Goodreads website:\n",
    "\n",
    "- _Viewed_: The user looked at a book description and saved it to their personal library.\n",
    "- _Read_: The user marked the book as \"read.\"\n",
    "- _Rated_: The user gave the book a rating, from 1 to 5 stars.\n",
    "- _Reviewed_: The user wrote a public review of the book on the website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These interactions are recorded in a SQL table called `Interactions`. Let's have a quick look for one of the users whose integer ID is `874199`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(r\"SELECT * FROM Interactions WHERE user_id=874199\", grdbconn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row shows how this user interacted with some book. Here are some insights:\n",
    "- This user interacted with nine books.\n",
    "- They reviewed two of these books.\n",
    "- They rated three of these books.\n",
    "- They read all but one of the books they saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to group the interactions and count the number by group. For example, we might want to know, for each unique user ID, how many interactions there are. Complete the function\n",
    "```python\n",
    "def count_interactions_by(col, conn):\n",
    "    ...\n",
    "```\n",
    "so that it does the following.\n",
    "\n",
    "**Inputs:**\n",
    "- `col`: The name of a column\n",
    "- `conn`: A database connection containing a table named `Interactions`\n",
    "\n",
    "**Your task:** For each unique value in column `'col'` of the `Interactions` table, count how many interactions (rows) there are.\n",
    "\n",
    "**Output:** Return a dataframe with two columns:\n",
    "- `col`: A column with the **same name** as the given input column holding the unique values\n",
    "- `'count'`: A column with the number of interactions for each unique value\n",
    "\n",
    "Refer to the demo cell below for an example of this output.\n",
    "\n",
    "**Additional notes and hints:** You may assume that `col` holds a valid column name. The exact order of rows and columns in your output does not matter.\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define demo inputs ###\n",
    "\n",
    "demo_col_ex1 = 'user_id'\n",
    "demo_conn_ex1 = db.connect(f'file:resources/demo_ex1.db?mode=ro', uri=True)\n",
    "display(pd.read_sql(\"SELECT * FROM Interactions\", demo_conn_ex1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `count_interactions_by(demo_col_ex1, demo_conn_ex1)` should produce the following output:\n",
    "\n",
    "|   user_id |   count |\n",
    "|----------:|--------:|\n",
    "|    569241 |       3 |\n",
    "|    604656 |       1 |\n",
    "|    607817 |       4 |\n",
    "\n",
    "However, calling `count_interactions_by('is_read', demo_conn_ex1)` would return a two-row `DataFrame` where the count of `0` and `1` values is `4` each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exercise 1 solution\n",
    "def count_interactions_by(col, conn):\n",
    "    ### BEGIN SOLUTION\n",
    "    '''Strategy:\n",
    "    1. Define our query by in Python (line 9)\n",
    "       - We SELECT our variables from the desired table\n",
    "    2. Use pandas to read the query (line 10)\n",
    "    '''\n",
    "    query = \"SELECT col, COUNT(*) FROM Interactions\"\n",
    "    return pd.read_sql(query, conn)\n",
    "    ### END SOLUTION\n",
    "\n",
    "### demo function calls ###\n",
    "display(count_interactions_by(demo_col_ex1, demo_conn_ex1))\n",
    "display(count_interactions_by('is_read', demo_conn_ex1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 1. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution.\n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test_cell_ex1\n",
    "\n",
    "from tester_fw.testers import Tester\n",
    "\n",
    "conf = {\n",
    "    'case_file':'tc_1',\n",
    "    'func': count_interactions_by, # replace this with the function defined above\n",
    "    'inputs':{ # input config dict. keys are parameter names\n",
    "        'col': {\n",
    "            'dtype': 'str', # data type of param.\n",
    "            'check_modified': False,\n",
    "        },\n",
    "        'conn': {\n",
    "            'dtype': 'db',\n",
    "            'check_modified': False\n",
    "        }\n",
    "    },\n",
    "    'outputs':{\n",
    "        'output_0':{\n",
    "            'index':0,\n",
    "            'dtype':'df',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
    "            'check_col_order': False, # Ignored if dtype is not df\n",
    "            'check_row_order': False, # Ignored if dtype is not df\n",
    "#            'check_column_type': True, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "tester = Tester(conf, key=b'jpS7W-CpqAQfuITMEQZL-yVXfhIaCkSaei-emnyRtrI=', path='resources/')\n",
    "for _ in range(70):\n",
    "    try:\n",
    "        tester.run_test()\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RUN ME:** A correct implementation of `count_interactions_by`, when run on the full Goodreads dataset for the columns `is_read`, `rating`, and `is_reviewed`, would produce the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== `count_interactions_by` on the full dataset ===\\n\")\n",
    "for col_ in ['is_read', 'rating', 'is_reviewed']:\n",
    "    display(load_df_from_file(f\"ex1-{col_}.df\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Aside (skip if pressed for time)**: From these results, you might observe a _hint_ at a phenomenon known as a [_monotonic behavior chain_](https://dl.acm.org/doi/10.1145/3240323.3240369): the total number of interactions > the number who read > the number who rate > the number who review. Such phenomena have been used to improve automatic generation of item recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ex. 5 (2 pts)**: `connect_users`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Given the analysis sample from Exercise 4, let's \"connect\" users.\n",
    "\n",
    "Let's say that two users `a` and `b` are **connected** if they both gave ratings of 4 or higher to the same book. The number of unique books they both rated this way is a measure of how strong their connection is.\n",
    "\n",
    "Complete the following function to help identify these connections.\n",
    "```python\n",
    "def connect_users(ubdf, threshold):\n",
    "    ...\n",
    "```\n",
    "\n",
    "**Inputs:**\n",
    "- `ubdf`: A \"user-book\" dataframe having these two columns: `user_id` and `book_id`. Each row indicates that a given user gave a given book a rating of 4 or higher.\n",
    "- `threshold`: An integer threshold on connection strength.\n",
    "\n",
    "**Your tasks:** Determine which pairs of users are connected. Count how many books connect them. Drop self-pairs (`user_id_x == user_id_y`), as well as any pairs with fewer than `threshold` connections.\n",
    "\n",
    "**Outputs:** Return a **new** `DataFrame` with three columns:\n",
    "1. `user_id_x`: A user ID\n",
    "2. `user_id_y`: Another user ID\n",
    "3. `count`: The number of books they both rated in common. Recall that this value should be `>= threshold`.\n",
    "\n",
    "**Additional notes and hints.**\n",
    "1. Omit self-pairs, that is, cases where `user_id_x` == `user_id_y`.\n",
    "1. Return pairs **symmetrically**. That is, if the pair of users (`a`, `b`) have a count `k` at or above the threshold, then **both** (`a`, `b`, `k`) and (`b`, `a`, `k`) should be rows in the output table.\n",
    "1. If no connections meet the threshold, you should return an empty `DataFrame` _with_ the specified columns.\n",
    "1. You may assume there are no duplicate rows.\n",
    "\n",
    "> _Aside:_ For really huge datasets (not what is included in this exam), dropping users with fewer than `threshold` ratings _before_ looking for pairs might be a bit faster.\n",
    "\n",
    "**Example:** Suppose the inputs are the `DataFrame` shown below with a target connection threshold of `2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define demo inputs ###\n",
    "\n",
    "demo_ubdf_ex5 = load_df_from_file(\"demo_ex5.df\").sort_values(['book_id', 'user_id']).reset_index(drop=True)\n",
    "demo_threshold_ex5 = 2\n",
    "\n",
    "display(demo_ubdf_ex5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this input, `connect_users` should produce:\n",
    "\n",
    "|   user_id_x |   user_id_y |   count |\n",
    "|------------:|------------:|--------:|\n",
    "|           0 |           2 |       2 |\n",
    "|           0 |           3 |       2 |\n",
    "|           2 |           0 |       2 |\n",
    "|           3 |           0 |       2 |\n",
    "\n",
    "Users `0` and `2` both rated books `7` and `19`, so they meet the threshold of having reviewed 2 books in common. User `1` did not review any books in common with any other user, and so they do not appear in any pair of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exercise 5 solution\n",
    "def connect_users(ubdf, threshold):\n",
    "    ### BEGIN SOLUTION\n",
    "    '''Strategy:\n",
    "    1. Perform a cross-join on our user table by book ID (13)\n",
    "    2. Group by pairs of users (14)\n",
    "    3. Count the pairs (15)\n",
    "    4. Reset our index and rename the variable (16-17)\n",
    "    5. Create a symmetric dataframe and append it to the original (18-22)\n",
    "    6. Select cases where the count is greater than the threshold (23)\n",
    "    7. Reset the index and return the dataframe(24-25)\n",
    "    '''\n",
    "    uudf = ubdf.merge(ubdf, on='book_id') \\\n",
    "               .groupby(['user_id_x', 'user_id_y']) \\\n",
    "               .size() \\\n",
    "               .reset_index() \\\n",
    "               .rename(columns={0: 'count'})\n",
    "    symmetric_uudf = uudf.rename(columns={\n",
    "        \"user_id_x\": \"user_id_y\",\n",
    "        \"user_id_y\": \"user_id_x\"}\n",
    "    )\n",
    "    uudf = pd.concat((uudf, symmetric_uudf))\n",
    "    uudf = uudf[uudf['count'] > threshold]\n",
    "    uudf = uudf.reset_index(drop=True)\n",
    "    return uudf\n",
    "    ### END SOLUTION\n",
    "\n",
    "### demo function call ###\n",
    "connect_users(demo_ubdf_ex5, demo_threshold_ex5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 5. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution.\n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test_cell_ex5\n",
    "from tester_fw.testers import Tester\n",
    "\n",
    "conf = {\n",
    "    'case_file':'tc_5',\n",
    "    'func': connect_users, # replace this with the function defined above\n",
    "    'inputs':{ # input config dict. keys are parameter names\n",
    "        'ubdf': {\n",
    "            'dtype': 'df', # data type of param.\n",
    "            'check_modified': True\n",
    "        },\n",
    "        'threshold': {\n",
    "            'dtype': 'int',\n",
    "            'check_modified': False\n",
    "        }\n",
    "    },\n",
    "    'outputs':{\n",
    "        'output_0':{\n",
    "            'index': 0,\n",
    "            'dtype': 'df',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
    "            'check_col_order': False, # Ignored if dtype is not df\n",
    "            'check_row_order': False, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "tester = Tester(conf, key=b'jpS7W-CpqAQfuITMEQZL-yVXfhIaCkSaei-emnyRtrI=', path='resources/')\n",
    "for _ in range(70):\n",
    "    try:\n",
    "        tester.run_test()\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RUN ME:** From a correct implementation of `connect_users`, one way we can \"draw\" the connectivity is to form a sparse matrix where nonzeros represent connections. Here is a picture of this matrix for the full dataset, using a threshold of 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uudf = load_df_from_file('ex5.df') # user-user table\n",
    "\n",
    "print(\"A sample of connections:\")\n",
    "display(uudf.head())\n",
    "\n",
    "if False: # Disabled due to NetworkX version incompatibility issue (fix pending)\n",
    "    uudf_G = cse6040.utils.to_nx(uudf.to_records(index=False))\n",
    "    ax_ex5 = cse6040.utils.graph_spy(uudf_G, markersize=0.01)\n",
    "    ax_ex5.set_title('Spy plot: user-user interactions')\n",
    "    ax_ex5.set_xlabel('user id')\n",
    "    ax_ex5.set_ylabel('user id', rotation=0, horizontalalignment='right');\n",
    "else:\n",
    "#     cse6040.utils.display_image_from_file('demo-user-user-spy.png')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ex. 6 (2 pts)**: `assign_communities`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background: Identifying \"top reads\" by community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Includes details for Exercise 6 (2 points) and Exercise 7 (1 point).\n",
    "\n",
    "The NetworkX package contains several algorithms for **detecting communities**, that is, clusters of \"strongly interconnected\" vertices in a graph (recall Part C).\n",
    "\n",
    "We ran one of these algorithms on a graph formed from the user-user interactions you calculated in Part D. The algorithm grouped users (graph vertices) into clusters.\n",
    "\n",
    "It returned these clusters as a **list of sets**, where each set is a \"community\" of user IDs grouped together. Since users were connected for liking the same books, it's possible users in the same community have similar tastes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the communities object that NetworkX produced for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = load_obj_from_file('demo_ex6.obj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a list of sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(communities), type(communities[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how many communities there are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(communities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sizes of the 6 communities are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(c) for c in communities]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the smaller two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Community 1:\", communities[1])\n",
    "print(\"Community 4:\", communities[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values you see are user IDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To merge this data with our existing database, we need to convert the Python `communities` data structure into a `DataFrame`. Complete the function below to aid in this task:\n",
    "\n",
    "```python\n",
    "def assign_communities(communities):\n",
    "    ...\n",
    "```\n",
    "\n",
    "**Inputs:** The input `communities` is a list of sets of integers, as in the previous example.\n",
    "\n",
    "**Your task:** Convert this input into a dataframe.\n",
    "\n",
    "**Returns:** Your function should return a `DataFrame` with these columns:\n",
    "- `user_id`: A user ID (an integer).\n",
    "- `comm_id`: The ID of the community it belongs to (also an integer).\n",
    "\n",
    "The community ID is its index in `communities`. That is, community `0` is stored in `communities[0]`, community `1` is in `communities[1]`, and so on.\n",
    "\n",
    "**Example:** Consider this set of communities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define demo inputs ###\n",
    "\n",
    "demo_communities_ex6 = [{1, 3, 10, 17}, {2, 6, 13, 15}, {0, 5, 11, 16}, {9, 14}, {4, 7, 8, 12}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A correct implementation of `assign_communities` would produce this result:\n",
    "\n",
    "|   user_id |   comm_id |\n",
    "|----------:|----------:|\n",
    "|         1 |         0 |\n",
    "|        10 |         0 |\n",
    "|         3 |         0 |\n",
    "|        17 |         0 |\n",
    "|         2 |         1 |\n",
    "|        13 |         1 |\n",
    "|         6 |         1 |\n",
    "|        15 |         1 |\n",
    "|         0 |         2 |\n",
    "|        16 |         2 |\n",
    "|        11 |         2 |\n",
    "|         5 |         2 |\n",
    "|         9 |         3 |\n",
    "|        14 |         3 |\n",
    "|         8 |         4 |\n",
    "|         4 |         4 |\n",
    "|        12 |         4 |\n",
    "|         7 |         4 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exercise 6 solution\n",
    "def assign_communities(communities):\n",
    "    ### BEGIN SOLUTION\n",
    "    '''Strategy:\n",
    "    1. Create lists for our user IDs and community IDs\n",
    "    2. Create a tracker to keep count of which community we're on\n",
    "    3. Loop over each community\n",
    "       3.1 Append our user ids to our list of all user IDs\n",
    "       3.2 Append the community ID, of length equal to the size of the\n",
    "           community, to our community ID list\n",
    "       3.3 Increment our community ID\n",
    "    4. Create a dataframe from our lists and return it\n",
    "    '''\n",
    "    from pandas import DataFrame\n",
    "    all_uids = []\n",
    "    all_cids = []\n",
    "    cid_tracker = 1.0\n",
    "    for uids in communities:\n",
    "        all_uids += list(uids)\n",
    "        all_cids += [cid_tracker] * len(communities)\n",
    "        cid_tracker += 1\n",
    "    return DataFrame({'user_ID': all_uids, 'comm_ID': all_cids})\n",
    "    ### END SOLUTION\n",
    "\n",
    "### demo function call ###\n",
    "assign_communities(demo_communities_ex6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 6. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution.\n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test_cell_ex6\n",
    "from tester_fw.testers import Tester\n",
    "\n",
    "conf = {\n",
    "    'case_file':'tc_6',\n",
    "    'func': assign_communities, # replace this with the function defined above\n",
    "    'inputs':{ # input config dict. keys are parameter names\n",
    "        'communities': {\n",
    "            'dtype': 'list', # data type of param.\n",
    "            'check_modified': True,\n",
    "        }\n",
    "    },\n",
    "    'outputs':{\n",
    "        'output_0':{\n",
    "            'index': 0,\n",
    "            'dtype': 'df',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
    "            'check_col_order': False, # Ignored if dtype is not df\n",
    "            'check_row_order': False, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "tester = Tester(conf, key=b'jpS7W-CpqAQfuITMEQZL-yVXfhIaCkSaei-emnyRtrI=', path='resources/')\n",
    "for _ in range(70):\n",
    "    try:\n",
    "        tester.run_test()\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ex. 7 (1 pt)**: `means_by_community`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Suppose we wish to calculate means (averages) of the interaction data _by community._ Implement the function,\n",
    "\n",
    "```python\n",
    "def means_by_community(intdf, comdf):\n",
    "    ...\n",
    "```\n",
    "\n",
    "to perform this task.\n",
    "\n",
    "**Inputs:**\n",
    "1. `intdf`: An interactions `DataFrame` with columns `user_id`, `book_id`, `is_read`, `rating`, and `is_reviewed`.\n",
    "1. `comdf`: A communities `DataFrame` with columns `user_id` and `comm_id`.\n",
    "\n",
    "**Your task:** Join these `DataFrames` and then return a new `DataFrame` with the mean values of the `is_read`, `rating`, and `is_reviewed` columns **by community.**\n",
    "\n",
    "**Outputs:** Your function should return a new `DataFrame` with these columns:\n",
    "1. `comm_id`: An integer community ID, one per row.\n",
    "2. `is_read`, `rating`, `is_reviewed`: The mean value of each column for all rows of `intdf` for all users of the community. These should be stored as `float` values.\n",
    "\n",
    "**Additional notes:** A user ID might not appear in both inputs. These should not be part of any means calculation.\n",
    "\n",
    "**Example:** Consider the following two inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define demo inputs ###\n",
    "\n",
    "demo_intdf_ex7 = load_table_from_db(\"Interactions\", \"demo_ex7.db\").sort_values(by='user_id')\n",
    "demo_comdf_ex7 = load_table_from_db(\"Communities\", \"demo_ex7.db\").sort_values(by='user_id')\n",
    "\n",
    "display(demo_intdf_ex7)\n",
    "display(demo_comdf_ex7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A correct implementation of `means_by_community` will return:\n",
    "\n",
    "|   comm_id |   is_read |   rating |   is_reviewed |\n",
    "|----------:|----------:|---------:|--------------:|\n",
    "|         0 |         1 |      4.0 |             0 |\n",
    "|         5 |         1 |      4.5 |             0 |\n",
    "\n",
    "Observe that user `25031` does not belong to any community. Therefore, none of the final averages should be affected by that user's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Exercise 7 solution\n",
    "def means_by_community(intdf, comdf):\n",
    "    ### BEGIN SOLUTION\n",
    "    '''Strategy:\n",
    "    1. Merge the two dataframes together with an outer join\n",
    "    2. Group the records by the comm_id variable and calculate the mean\n",
    "    3. Return the results\n",
    "    '''\n",
    "    df = intdf.merge(comdf, on='user_id', how='outer')\n",
    "    df = df.groupby('comm_id').mean()\n",
    "    return df\n",
    "    ### END SOLUTION\n",
    "\n",
    "### demo function call ###\n",
    "demo_result_ex7 = means_by_community(demo_intdf_ex7, demo_comdf_ex7)\n",
    "display(demo_result_ex7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 7. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution.\n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test_cell_ex7\n",
    "from tester_fw.testers import Tester\n",
    "\n",
    "conf = {\n",
    "    'case_file':'tc_7',\n",
    "    'func': means_by_community, # replace this with the function defined above\n",
    "    'inputs':{ # input config dict. keys are parameter names\n",
    "        'intdf': {\n",
    "            'dtype': 'df', # data type of param.\n",
    "            'check_modified': True,\n",
    "        },\n",
    "        'comdf': {\n",
    "            'dtype': 'df',\n",
    "            'check_modified': True\n",
    "        }\n",
    "    },\n",
    "    'outputs':{\n",
    "        'output_0':{\n",
    "            'index': 0,\n",
    "            'dtype': 'df',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
    "            'check_col_order': False, # Ignored if dtype is not df\n",
    "            'check_row_order': False, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "tester = Tester(conf, key=b'jpS7W-CpqAQfuITMEQZL-yVXfhIaCkSaei-emnyRtrI=', path='resources/')\n",
    "for _ in range(70):\n",
    "    try:\n",
    "        tester.run_test()\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RUN ME:** With a correct `means_by_community`, we can see whether the communities differ in how they read, rate, and review books. Here is what would happen if we ran on the full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex7_means = load_df_from_file('ex7-means.df')\n",
    "print(f\"Recall: community sizes: {[(k, len(c)) for k, c in enumerate(communities)]}\")\n",
    "ex7_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click the link below to see a version of this document with correct solutions.\n",
    "\n",
    "[![Click here to view the Solution Version](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gt-cse-6040/bootcamp/blob/main/Module%201/Session%208/m1s8nb1_Data_Debugging_part1%20-%20Solutions.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
