{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gt-cse-6040/bootcamp/blob/main/Module%201/Session%209/m1s9nb2_Data_Debugging_part2%20-%20Exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2ba5485-42c1-4186-97d1-29635d12e51f",
      "metadata": {
        "id": "a2ba5485-42c1-4186-97d1-29635d12e51f"
      },
      "source": [
        "# Debugging Bad Solutions: Module 1, Part 2\n",
        "\n",
        "From Midterm 2, Fall 2022 - Two and Three-Point Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cf1e752-a17d-4a8d-a7b5-fdfbb220a55e",
      "metadata": {
        "id": "7cf1e752-a17d-4a8d-a7b5-fdfbb220a55e"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dill\n",
        "\n",
        "!mkdir resources\n",
        "%cd resources\n",
        "\n",
        "!wget https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%209/resources/tc_1\n",
        "!wget https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%209/resources/tc_3\n",
        "!wget https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%209/resources/tc_5\n",
        "\n",
        "%cd ..\n",
        "\n",
        "!mkdir tester_fw\n",
        "%cd tester_fw\n",
        "\n",
        "!wget https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%209/tester_fw/__init__.py\n",
        "!wget https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%209/tester_fw/test_utils.py\n",
        "!wget https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%209/tester_fw/testers.py\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQm12E9z6RpE",
        "outputId": "3ff822d4-cf01-4e63-ab2a-7dbd96e9a8a7"
      },
      "id": "dQm12E9z6RpE",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "/content/resources\n",
            "--2023-12-24 17:51:48--  https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%209/resources/tc_1\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8159884 (7.8M) [text/plain]\n",
            "Saving to: ‘tc_1’\n",
            "\n",
            "tc_1                100%[===================>]   7.78M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-12-24 17:51:48 (113 MB/s) - ‘tc_1’ saved [8159884/8159884]\n",
            "\n",
            "--2023-12-24 17:51:48--  https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%209/resources/tc_3\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17747404 (17M) [text/plain]\n",
            "Saving to: ‘tc_3’\n",
            "\n",
            "tc_3                100%[===================>]  16.92M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2023-12-24 17:51:48 (180 MB/s) - ‘tc_3’ saved [17747404/17747404]\n",
            "\n",
            "--2023-12-24 17:51:48--  https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%209/resources/tc_5\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10173240 (9.7M) [text/plain]\n",
            "Saving to: ‘tc_5’\n",
            "\n",
            "tc_5                100%[===================>]   9.70M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-12-24 17:51:48 (144 MB/s) - ‘tc_5’ saved [10173240/10173240]\n",
            "\n",
            "/content\n",
            "mkdir: cannot create directory ‘tester_fw’: File exists\n",
            "/content/tester_fw\n",
            "--2023-12-24 17:51:48--  https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%209/tester_fw/__init__.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4701 (4.6K) [text/plain]\n",
            "Saving to: ‘__init__.py.2’\n",
            "\n",
            "__init__.py.2       100%[===================>]   4.59K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-24 17:51:48 (65.7 MB/s) - ‘__init__.py.2’ saved [4701/4701]\n",
            "\n",
            "--2023-12-24 17:51:49--  https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%209/tester_fw/test_utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3997 (3.9K) [text/plain]\n",
            "Saving to: ‘test_utils.py.2’\n",
            "\n",
            "test_utils.py.2     100%[===================>]   3.90K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-24 17:51:49 (68.6 MB/s) - ‘test_utils.py.2’ saved [3997/3997]\n",
            "\n",
            "--2023-12-24 17:51:49--  https://raw.githubusercontent.com/gt-cse-6040/bootcamp/main/Module%201/Session%209/tester_fw/testers.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4557 (4.5K) [text/plain]\n",
            "Saving to: ‘testers.py.2’\n",
            "\n",
            "testers.py.2        100%[===================>]   4.45K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-24 17:51:49 (47.3 MB/s) - ‘testers.py.2’ saved [4557/4557]\n",
            "\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "255cf4c3-79da-4c2d-a45a-775d011878f4",
      "metadata": {
        "id": "255cf4c3-79da-4c2d-a45a-775d011878f4"
      },
      "source": [
        "### Purpose\n",
        "\n",
        "On the exams you may initially write solutions that do not pass the test cases. That's okay! You will need to debug your code to determine what is causing the issue(s) and then figure out to how fix them. So how can we get better at debugging? We practice!\n",
        "\n",
        "Below are exercises from the Fall 2022 Midterm 2. We have pre-written solutions for each exercise that are \"bad\" in one or more ways. Our solutions may contain one or more logic and/or syntax errors. . Can you find and fix the issues in each exercise and pass all of the test cases?\n",
        "\n",
        "**Debugging your code:** Right before each exercise test cell, there is a block of text explaining the variables available to you for debugging. You may use these to test your code and can print/display them as needed (careful when printing large objects, you may want to print the head or chunks of rows at a time).\n",
        "\n",
        "**Exercise point breakdown:**\n",
        "\n",
        "- Exercise 1: **2** point(s)\n",
        "- Exercise 3: **2** point(s)\n",
        "- Exercise 5: **3** point(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbbff24b-69b7-407a-9b34-aaedfc437123",
      "metadata": {
        "id": "dbbff24b-69b7-407a-9b34-aaedfc437123"
      },
      "source": [
        "## Scenario (don't dwell on this)\n",
        "\n",
        "You have just been hired by the hot new startup **Spot-i-flix-ify** (this is a fictional company which will offer video and audio streaming services) as a Data Scientist. This is a small startup so you have to \"wear many different hats,\" so to speak. Your first task on the job is to set up their data warehousing so that they can capture a historical record of their operations for analysis later. The operational database (which someone else has already set up) only contains the current state of the operation to maintain maximum efficiency while performing tasks like adding new customers, changing services, applying promotions, etc. It will not contain any history and is not intended have complex queries run against it.\n",
        "  \n",
        "While this is a fictional company and simulation data, **there is a real-world use case** for the processes developed in this notebook.\n",
        "\n",
        "## On data types\n",
        "These tables are made available to you in a staging environment as Pandas `DataFrame` objects. **All columns in all of the DataFrames are strings (even the columns where you would expect other data types)**.\n",
        "\n",
        "## On SQL\n",
        "We used Pandas exclusively in developing this problem, however some exercise are solvable using SQL. In the cell below we have included the function `dfs_to_conn` which can be used to create in-memory database connections. If you pass in a dictionary mapping table names to DataFrames, `dfs_to_conn` will return a sqlite 3 connection with all of the data in the DataFrames available under the names given as keys. You are also free to write to the in-memory database by creating tables, inserting/deleting/updating records, etc. Anything that SQLite allows should work!\n",
        "\n",
        "Example:\n",
        "  ```\n",
        "my_df = pd.DataFrame({'A':[1,2,3], 'B': [4,5,6], 'C':['x', 'y', 'z']})\n",
        "print(my_df)\n",
        "#    A  B  C\n",
        "# 0  1  4  x\n",
        "# 1  2  5  y\n",
        "# 2  3  6  z\n",
        "conn = dfs_to_conn({'my_table': my_df})\n",
        "cur = conn.cursor()\n",
        "cur.execute('select A, B, C from my_table')\n",
        "result = cur.fetchall()\n",
        "conn.close()\n",
        "print(result) # list of tuples, each tuple is a row\n",
        "#[(1, 4, 'x'), (2, 5, 'y'), (3, 6, 'z')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cdc3fea7-7492-4ea8-81b6-d1181df83c60",
      "metadata": {
        "id": "cdc3fea7-7492-4ea8-81b6-d1181df83c60"
      },
      "outputs": [],
      "source": [
        "### Global Imports\n",
        "###\n",
        "### AUTOGRADER TEST - DO NOT REMOVE\n",
        "###\n",
        "import pandas as pd\n",
        "import time\n",
        "overall_start = time.time()\n",
        "\n",
        "def dfs_to_conn(conn_dfs, index=False):\n",
        "    import sqlite3\n",
        "    conn = sqlite3.connect(':memory:')\n",
        "    for table_name, df in conn_dfs.items():\n",
        "        df.to_sql(table_name, conn, if_exists='replace', index=index)\n",
        "    return conn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "aeadb4ba-08aa-4261-8836-63a882f4d781",
      "metadata": {
        "id": "aeadb4ba-08aa-4261-8836-63a882f4d781"
      },
      "outputs": [],
      "source": [
        "# !python -m pip install -r resources/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f2bf174-82b0-4c8f-8985-df2a60da800c",
      "metadata": {
        "id": "5f2bf174-82b0-4c8f-8985-df2a60da800c"
      },
      "source": [
        "## Data (Don't dwell on this. The structures you are working with will be explained in each exercise.)\n",
        "You are working with four tables:\n",
        "- `customers` - Center of the \"star\" schema. Primary Key: `id`.\n",
        "  - `customers.id` - a unique identifier for an individual customer.\n",
        "  - `customers.paid` - ('True'|'False') - indicates whether a customer has paid their bill for their upcoming month of service.\n",
        "- `prices` - The prices of the services offered by **Spot-i-flix-ify**. Primary Key: `service, tier, promo`\n",
        "  - `prices.service` - Name of the sevice\n",
        "  - `prices.tier` - Tier of the service. A service can be offered in several tiers. Higher tiers give customers more features.\n",
        "  - `prices.promo` - Promotion which can be applied to a service/tier combination to offer a discount to customers.\n",
        "  - `prices.price` - The price of a particular service/tier/promo combination.\n",
        "- `services` - Services which each customer is subscribed. Primary Key: `cust_id, service`; Foreign Keys: `cust_id` references `customers.id`, (`service, tier`) references (`prices.service, prices.tier`)\n",
        "  - `services.cust_id` - id of the customer associated with this subscription.\n",
        "  - `services.service` - name of service associated with this subscription.\n",
        "  - `services.tier` - tier of service associated with a subscription.\n",
        "- `active_promos` - the promotion which is actually applied to each customer for a particular service\n",
        "  - `'cust_id'` - identifies an individual customer.\n",
        "  - `'service'` - identifies a service for which the customer has an active promotion. **The customer may not actually be subscribed to the service!**\n",
        "  - `'promo'` - the active promo for the `cust_id`/`service` pair.\n",
        "    - If `'time_left'` is '0' for all records associated with the `cust_id`/`service` pair in `promos`, this column should have a value of `'base'`.\n",
        "    - If there is a record associated with a non-zero `'time_left'`, this column should have the `'promo'` from that record."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d134218f-6a49-4b4d-ad72-19375c0dabd3",
      "metadata": {
        "id": "d134218f-6a49-4b4d-ad72-19375c0dabd3"
      },
      "source": [
        "## Exercise 1 - (**2** Points):  \n",
        "\n",
        "**Requirements**:  \n",
        "Define the function `denormalize(customers, services, active_promos, prices)` which takes the DataFrame inputs defined above. See the data model diagram for the relationships between the 4 tables.\n",
        "\n",
        "![data_model](https://github.com/gt-cse-6040/bootcamp/blob/main/Module%201/Session%209/resources/schema.png?raw=1)\n",
        "\n",
        "  Your function should return a DataFrame `df` which contains the following columns:\n",
        "  - `id` - identifies a particular customer (from `customers`)\n",
        "  - `paid` - ('True'|'False') indicating whether the customer `id` has paid their bill (from `customers`)\n",
        "  - `service` - a service which a customer is subscribed. There should be one record for each unique `id`/`service` pair (from `services`)\n",
        "  - `tier` - tier of a service for the `id`/`service` pair. (from `services`)\n",
        "  - `promo` - promo being applied to the `id`/`service` pair. (from `active_promos`)\n",
        "      - Remember that a record existing with a `cust_id`/`service` combination in `active_promos` _does not imply the customer is subscribed to that service_.\n",
        "  - `price` - price charged for the `id`/`service` pair (from `prices`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a7470406-802a-48be-b316-ae4be04734af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7470406-802a-48be-b316-ae4be04734af",
        "outputId": "d89186af-4af2-464e-ac33-ed4829fcc87c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "customers\n",
            "  id   paid\n",
            "0  0   True\n",
            "1  1  False\n",
            "\n",
            "services\n",
            "  cust_id service tier\n",
            "0       0   audio    1\n",
            "1       1   video    1\n",
            "2       1   audio    2\n",
            "\n",
            "active_promos\n",
            "  cust_id service  promo\n",
            "0       0   audio  intro\n",
            "1       0   video   base\n",
            "2       1   audio   base\n",
            "3       1   video  intro\n",
            "\n",
            "prices\n",
            "  service tier  promo  price\n",
            "0   audio    1   base   8.99\n",
            "1   audio    1  intro   5.99\n",
            "2   audio    2   base  12.99\n",
            "3   audio    2  intro   9.99\n",
            "4   video    1   base  10.99\n",
            "5   video    1  intro   8.99\n",
            "6   video    2   base  15.99\n",
            "7   video    2  intro  11.99\n"
          ]
        }
      ],
      "source": [
        "### Define demo inputs\n",
        "\n",
        "demo_customers_ex1 = pd.DataFrame({'id': {0: '0', 1: '1'}, 'paid': {0: 'True', 1: 'False'}})\n",
        "demo_active_promos_ex1 = pd.DataFrame({'cust_id': {0: '0', 1: '0', 2: '1', 3: '1'},\n",
        " 'service': {0: 'audio', 1: 'video', 2: 'audio', 3: 'video'},\n",
        " 'promo': {0: 'intro', 1: 'base', 2: 'base', 3: 'intro'}})\n",
        "demo_prices_ex1 = pd.DataFrame(\n",
        "    {'service': {0: 'audio',  1: 'audio',  2: 'audio',  3: 'audio',  4: 'video',  5: 'video',  6: 'video',  7: 'video'},\n",
        "    'tier': {0: '1', 1: '1', 2: '2', 3: '2', 4: '1', 5: '1', 6: '2', 7: '2'},\n",
        "    'promo': {0: 'base', 1: 'intro', 2: 'base', 3: 'intro', 4: 'base', 5: 'intro', 6: 'base', 7: 'intro'},\n",
        "    'price': {0: '8.99', 1: '5.99', 2: '12.99', 3: '9.99', 4: '10.99', 5: '8.99', 6: '15.99', 7: '11.99'}})\n",
        "demo_services_ex1 = pd.DataFrame({'cust_id': {0: '0', 1: '1', 2: '1'},\n",
        " 'service': {0: 'audio', 1: 'video', 2: 'audio'},\n",
        " 'tier': {0: '1', 1: '1', 2: '2'}})\n",
        "\n",
        "print('customers')\n",
        "print(demo_customers_ex1)\n",
        "print()\n",
        "print('services')\n",
        "print(demo_services_ex1)\n",
        "print()\n",
        "print('active_promos')\n",
        "print(demo_active_promos_ex1)\n",
        "print()\n",
        "print('prices')\n",
        "print(demo_prices_ex1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d0ea2520-9f84-4092-85ff-bc0031a6226b",
      "metadata": {
        "id": "d0ea2520-9f84-4092-85ff-bc0031a6226b"
      },
      "outputs": [],
      "source": [
        "outline = '''\n",
        "output:\n",
        "    - df\n",
        "        - data_type == DataFrame\n",
        "        - cols:\n",
        "            - customers.id, customers.paid\n",
        "            - services.service, services.tier\n",
        "            - active_promos.promo of a subscribed id/service pair\n",
        "            - prices.price of an id/service pair\n",
        "        - grain == one row per cust_id + service\n",
        "        - column types are strings\n",
        "inputs:\n",
        "    - customers, services, active_promos, prices\n",
        "        - data_type == DataFrame\n",
        "steps:\n",
        "    1. we want to return all customers + the services they're currently paying for\n",
        "        - JOIN services\n",
        "    2. we want the active promo for the current services\n",
        "        - JOIN active_promos\n",
        "    3. we want the prices for the active promo\n",
        "        - JOIN prices\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ab60d0c3-c8fe-4c74-9464-02ddfb863bd4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab60d0c3-c8fe-4c74-9464-02ddfb863bd4",
        "outputId": "ca491d8c-c70c-4c9b-a9f5-12eaf30e8c4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id   paid service tier  promo  price\n",
            "0   0   True   audio    1   base  12.99\n",
            "1   0   True   audio    1   base   5.99\n",
            "2   0   True   audio    1   base   8.99\n",
            "3   0   True   audio    1   base   9.99\n",
            "4   0   True   audio    1  intro  12.99\n",
            "5   0   True   audio    1  intro   5.99\n",
            "6   0   True   audio    1  intro   8.99\n",
            "7   0   True   audio    1  intro   9.99\n",
            "8   1  False   audio    2   base  12.99\n",
            "9   1  False   audio    2   base   5.99\n",
            "10  1  False   audio    2   base   8.99\n",
            "11  1  False   audio    2   base   9.99\n",
            "12  1  False   audio    2  intro  12.99\n",
            "13  1  False   audio    2  intro   5.99\n",
            "14  1  False   audio    2  intro   8.99\n",
            "15  1  False   audio    2  intro   9.99\n",
            "16  1  False   video    1   base  10.99\n",
            "17  1  False   video    1   base  11.99\n",
            "18  1  False   video    1   base  15.99\n",
            "19  1  False   video    1   base   8.99\n",
            "20  1  False   video    1  intro  10.99\n",
            "21  1  False   video    1  intro  11.99\n",
            "22  1  False   video    1  intro  15.99\n",
            "23  1  False   video    1  intro   8.99\n"
          ]
        }
      ],
      "source": [
        "### Exercise 1 solution\n",
        "def denormalize(customers, services, active_promos, prices):\n",
        "    ###\n",
        "    ### YOUR CODE HERE\n",
        "    ###\n",
        "\n",
        "    conn = dfs_to_conn({'customers': customers, 'services': services, 'active_promos': active_promos, 'prices': prices})\n",
        "    query = '''\n",
        "    SELECT\n",
        "        c.id\n",
        "      , c.paid\n",
        "      , s.service\n",
        "      , s.tier\n",
        "      , ap.promo\n",
        "      , p.price\n",
        "    FROM customers c\n",
        "    JOIN services s\n",
        "      ON c.id = s.cust_id\n",
        "    JOIN active_promos ap\n",
        "      ON c.id = ap.cust_id\n",
        "    JOIN prices p\n",
        "      ON s.service = p.service\n",
        "    '''\n",
        "\n",
        "    df = pd.read_sql_query(query, conn)\n",
        "    return df\n",
        "\n",
        "demo_ex1_output = denormalize(demo_customers_ex1, demo_services_ex1, demo_active_promos_ex1, demo_prices_ex1)\n",
        "print(demo_ex1_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5edcbc0-8dfa-4279-b75e-e529967cfdde",
      "metadata": {
        "id": "d5edcbc0-8dfa-4279-b75e-e529967cfdde"
      },
      "source": [
        "<!-- Test Cell Boilerplate -->\n",
        "The cell below will test your solution for Exercise 1. The testing variables will be available for debugging under the following names in a dictionary format.\n",
        "- `input_vars` - Input variables for your solution.\n",
        "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
        "- `returned_output_vars` - Outputs returned by your solution.\n",
        "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "55c21db1-7ba5-4638-a164-58ba9915824a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "55c21db1-7ba5-4638-a164-58ba9915824a",
        "outputId": "cd6e2475-afd2-4041-93db-595cf700d576"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0bdf21b25b2e>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mtester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0minput_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_input_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturned_output_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_output_vars\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_test_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/tester_fw/testers.py\u001b[0m in \u001b[0;36mrun_test\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/tester_fw/__init__.py\u001b[0m in \u001b[0;36mrun_test\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_modified\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Check to verify inputs were not modified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# Check to verify correct output types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# Check to verify correct output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/tester_fw/testers.py\u001b[0m in \u001b[0;36mcheck_matches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mout_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mtest_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturned_output_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             assert test_utils.compare_copies(a=test_var,\n\u001b[0m\u001b[1;32m     84\u001b[0m                                             \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrue_output_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                                             \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'float_tolerance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: \nOutput for output_0 is incorrect.\nThe returned result is available as `returned_output_vars['output_0']`\nThe expected result is available as `true_output_vars['output_0']`\n            "
          ]
        }
      ],
      "source": [
        "### test_cell_ex1\n",
        "\n",
        "exercise_start = time.time()\n",
        "from tester_fw.testers import Tester\n",
        "\n",
        "conf = {\n",
        "    'case_file':'tc_1',\n",
        "    'func': denormalize, # replace this with the function defined above\n",
        "    'inputs':{ # input config dict. keys are parameter names\n",
        "        'customers':{\n",
        "            'dtype':'pd.DataFrame', # data type of param.\n",
        "            'check_modified':True,\n",
        "        },\n",
        "        'services':{\n",
        "            'dtype':'pd.DataFrame', # data type of param.\n",
        "            'check_modified':True,\n",
        "        },\n",
        "        'active_promos':{\n",
        "            'dtype':'pd.DataFrame', # data type of param.\n",
        "            'check_modified':True,\n",
        "        },\n",
        "        'prices':{\n",
        "            'dtype':'pd.DataFrame', # data type of param.\n",
        "            'check_modified':True,\n",
        "        }\n",
        "    },\n",
        "    'outputs':{\n",
        "        'output_0':{\n",
        "            'index':0,\n",
        "            'dtype':'',\n",
        "            'check_dtype': True,\n",
        "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
        "            'check_col_order': False, # Ignored if dtype is not df\n",
        "            'check_row_order': False, # Ignored if dtype is not df\n",
        "            'check_column_type': True, # Ignored if dtype is not df\n",
        "            'float_tolerance': 10 ** (-6)\n",
        "        }\n",
        "    }\n",
        "}\n",
        "tester = Tester(conf, key=b'6IRWMcPsVIAZqzDJnPgv_MfUZsxqo4Utjm2Favidv-A=', path='resources/')\n",
        "for _ in range(70):\n",
        "    try:\n",
        "        tester.run_test()\n",
        "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
        "    except:\n",
        "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
        "        raise\n",
        "\n",
        "exercise_end = time.time()\n",
        "print(f\"This test executed in {(pd.to_datetime(exercise_end, unit='s') - pd.to_datetime(exercise_start, unit='s')).seconds} seconds\")\n",
        "print('Passed! Please submit.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6639cf5-afd8-44bf-92f1-3955e3308efb",
      "metadata": {
        "id": "b6639cf5-afd8-44bf-92f1-3955e3308efb"
      },
      "source": [
        "## Exercise 3 - (**2** Points):  \n",
        "**Motivation** (don't dwell on this):  \n",
        "\n",
        "The first task in our journaling process is to identify which records in the existing journal are active and which records are not. We will do so by checking the `'exp_dt'` column. All records with `'9999-12-31'` as their expiration date are considered active. We will be rebuilding the entire journal, so we need to partition the existing journal into active and not-active records and return both parts. The active records will be compared with the business data, and the inactive records will be included in the updated journal without modification. Additionally, on the initial load, there will not be an existing journal, so we will need to create it based on the data being loaded and the desired audit columns.\n",
        "\n",
        "**Requirements**:  \n",
        "Define `partition_journal(df, audit_cols, existing_journal=None)`.\n",
        "\n",
        "- The input `df` is a DataFrame - we do not care about it's structure.\n",
        "- The input `audit_cols` is a `list` of strings. These are the names of audit columns used to track history in the journal. `audit_cols` will always include the strings `'eff_dt'` and `'exp_dt'`.\n",
        "- The optional input `existing_journal` is a DataFrame or `None`.  If `existing_journal` is not `None` it will have all of the columns in `df` and all of the `audit_cols` as its columns.\n",
        "\n",
        "Your function should do the following:\n",
        "- If `existing_journal` is `None`, create an empty DataFrame which has all of the columns in `df` and all of the `audit_cols` as its columns. This empty DataFrame will be used in the subsequent operations.\n",
        "- Create `historical_journal` which is a DataFrame containing all rows of `existing_journal` where `'exp_dt'` is something other than `'9999-12-31'`.\n",
        "- Create `active_journal` which is a DataFrame containing all rows of `existing_journal` where `'exp_dt'` is `'9999-12-31'`.\n",
        "- Return the tuple `(historical_journal, active_journal)` - If the `existing_journal` was newly created these will be two empty DataFrames with all columns present in `df` and all of the `audit_cols`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "686d11b1-5277-40fa-aa05-c58f8a09e89e",
      "metadata": {
        "id": "686d11b1-5277-40fa-aa05-c58f8a09e89e"
      },
      "outputs": [],
      "source": [
        "### Define demo inputs\n",
        "\n",
        "demo_df_ex3 = pd.DataFrame({'id': {0: '1', 1: '2', 2: '2'},\n",
        " 'paid': {0: 'True', 1: 'True', 2: 'True'},\n",
        " 'service': {0: 'audio', 1: 'video', 2: 'audio'},\n",
        " 'tier': {0: '1', 1: '2', 2: '2'},\n",
        " 'promo': {0: 'base', 1: 'base', 2: 'base'},\n",
        " 'price': {0: '8.99', 1: '15.99', 2: '12.99'}})\n",
        "demo_existing_journal_ex3 = pd.DataFrame(\n",
        "    {'id': {667: '0', 668: '1', 669: '2', 670: '2', 671: '3', 672: '3', 673: '4', 9: '3', 10: '3', 17: '0', 1881: '1', 1882: '2', 1883: '2', 1884: '4'},\n",
        "    'paid': {667: 'True', 668: 'True', 669: 'True', 670: 'True', 671: 'True', 672: 'True', 673: 'True', 9: 'False', 10: 'False', 17: 'True',\n",
        "            1881: 'True', 1882: 'True', 1883: 'True', 1884: 'True'},\n",
        "    'service': {667: 'video', 668: 'audio', 669: 'video', 670: 'audio', 671: 'video', 672: 'audio', 673: 'audio', 9: 'video', 10: 'audio', 17: 'video',\n",
        "            1881: 'audio', 1882: 'video', 1883: 'audio', 1884: 'audio'},\n",
        "    'tier': {667: '2', 668: '1', 669: '2', 670: '2', 671: '1', 672: '1', 673: '1', 9: '1', 10: '1', 17: '2', 1881: '1', 1882: '2', 1883: '2', 1884: '1'},\n",
        "    'promo': {667: 'intro', 668: 'intro', 669: 'intro', 670: 'intro', 671: 'intro', 672: 'intro', 673: 'intro', 9: 'base', 10: 'base', 17: 'base',\n",
        "            1881: 'base', 1882: 'base', 1883: 'base', 1884: 'base'},\n",
        "    'price': {667: '11.99', 668: '5.99', 669: '11.99', 670: '9.99', 671: '8.99', 672: '5.99', 673: '5.99', 9: '10.99', 10: '8.99', 17: '15.99',\n",
        "            1881: '8.99', 1882: '15.99', 1883: '12.99', 1884: '8.99'},\n",
        "    'eff_dt': {667: '2018-02-01', 668: '2018-02-01', 669: '2018-02-01', 670: '2018-02-01', 671: '2018-02-01', 672: '2018-02-01', 673: '2018-02-01',\n",
        "            9: '2018-08-01', 10: '2018-08-01', 17: '2018-08-01', 1881: '2018-08-01', 1882: '2018-08-01', 1883: '2018-08-01', 1884: '2018-08-01'},\n",
        "    'exp_dt': {667: '2018-07-31', 668: '2018-07-31', 669: '2018-07-31', 670: '2018-07-31', 671: '2018-07-31', 672: '2018-07-31', 673: '2018-07-31',\n",
        "            9: '2018-08-31', 10: '2018-08-31', 17: '2019-02-28', 1881: '9999-12-31', 1882: '9999-12-31', 1883: '9999-12-31', 1884: '9999-12-31'}})\n",
        "demo_audit_cols_ex3 = ['eff_dt', 'exp_dt']\n",
        "\n",
        "print('df')\n",
        "print(demo_df_ex3)\n",
        "print()\n",
        "print('audit_cols')\n",
        "print(demo_audit_cols_ex3)\n",
        "print()\n",
        "print('existing_journal')\n",
        "print(demo_existing_journal_ex3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed5f000b-a024-41bc-aee9-a46e865d4fb4",
      "metadata": {
        "id": "ed5f000b-a024-41bc-aee9-a46e865d4fb4"
      },
      "source": [
        "<!-- Expected demo output text block -->\n",
        "The demo included in the solution cell below should display the following output:\n",
        "```\n",
        "historical_journal WITH NO existing journal\n",
        "Empty DataFrame\n",
        "Columns: [id, paid, service, tier, promo, price, eff_dt, exp_dt]\n",
        "Index: []\n",
        "\n",
        "active_journal WITH NO existing journal\n",
        "Empty DataFrame\n",
        "Columns: [id, paid, service, tier, promo, price, eff_dt, exp_dt]\n",
        "Index: []\n",
        "\n",
        "historical_journal WITH existing journal\n",
        "    id   paid service tier  promo  price      eff_dt      exp_dt\n",
        "667  0   True   video    2  intro  11.99  2018-02-01  2018-07-31\n",
        "668  1   True   audio    1  intro   5.99  2018-02-01  2018-07-31\n",
        "669  2   True   video    2  intro  11.99  2018-02-01  2018-07-31\n",
        "670  2   True   audio    2  intro   9.99  2018-02-01  2018-07-31\n",
        "671  3   True   video    1  intro   8.99  2018-02-01  2018-07-31\n",
        "672  3   True   audio    1  intro   5.99  2018-02-01  2018-07-31\n",
        "673  4   True   audio    1  intro   5.99  2018-02-01  2018-07-31\n",
        "9    3  False   video    1   base  10.99  2018-08-01  2018-08-31\n",
        "10   3  False   audio    1   base   8.99  2018-08-01  2018-08-31\n",
        "17   0   True   video    2   base  15.99  2018-08-01  2019-02-28\n",
        "\n",
        "active_journal WITH existing journal\n",
        "     id  paid service tier promo  price      eff_dt      exp_dt\n",
        "1881  1  True   audio    1  base   8.99  2018-08-01  9999-12-31\n",
        "1882  2  True   video    2  base  15.99  2018-08-01  9999-12-31\n",
        "1883  2  True   audio    2  base  12.99  2018-08-01  9999-12-31\n",
        "1884  4  True   audio    1  base   8.99  2018-08-01  9999-12-31\n",
        "```\n",
        "**Note** - This demo runs your solution two times. The first two DataFrames are the expected result when `exixting_journal` is `None`, and the second two DataFrames are the expected result for the `existing_journal` defined in the cell above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "912e67b7-f4eb-4c40-9a09-628bb759180a",
      "metadata": {
        "id": "912e67b7-f4eb-4c40-9a09-628bb759180a"
      },
      "outputs": [],
      "source": [
        "outline = '''\n",
        "output:\n",
        "    - (historical_journal, active_journal)\n",
        "        - data_type == tuple of dataframes\n",
        "inputs:\n",
        "    - df\n",
        "        - data_type == DataFrame\n",
        "    - audit_cols\n",
        "        - data_type == list of strings\n",
        "        - will always include eff_dt and exp_dt\n",
        "    - existing_journal\n",
        "        - data_type == df or None\n",
        "        - optional\n",
        "steps:\n",
        "    1. check if existing_journal is None\n",
        "        a. if yes: create empty df where existing_journal cols = df.cols + audit_cols\n",
        "    2. create journals\n",
        "        a. historical_journal = existing_journal where exp_dt != '9999-12-31'\n",
        "        b. active_journal = existing_journal where exp_dt = '9999-12-31'\n",
        "    3. return dfs\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b89dd57a-4b8a-4986-877d-bfd9544ca19e",
      "metadata": {
        "id": "b89dd57a-4b8a-4986-877d-bfd9544ca19e"
      },
      "outputs": [],
      "source": [
        "### Exercise 3 solution\n",
        "def partition_journal(df, audit_cols, existing_journal=None):\n",
        "    ###\n",
        "    ### YOUR CODE HERE\n",
        "    ###\n",
        "\n",
        "    if existing_journal is None:\n",
        "        list = list(df.columns)\n",
        "        empty_journal_cols = list + audit_cols\n",
        "        existing_journal = pd.DataFrame(columns=empty_journal_cols)\n",
        "\n",
        "    historical_journal = existing_journal[existing_journal['exp_dt'] != '9999-12-31']\n",
        "    active_journal = existing_journal[existing_journal['exp_dt'] = '9999-12-31']\n",
        "\n",
        "    return (active_journal, historical_journal)\n",
        "\n",
        "### demo function call\n",
        "new_hist, new_active = partition_journal(demo_df_ex3, demo_audit_cols_ex3)\n",
        "hist, active = partition_journal(demo_df_ex3, demo_audit_cols_ex3, demo_existing_journal_ex3)\n",
        "print('historical_journal WITH NO existing journal')\n",
        "print(new_hist)\n",
        "print()\n",
        "print('active_journal WITH NO existing journal')\n",
        "print(new_active)\n",
        "print()\n",
        "print('historical_journal WITH existing journal')\n",
        "print(hist)\n",
        "print()\n",
        "print('active_journal WITH existing journal')\n",
        "print(active)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12fb7dc5-0233-4882-86fd-808875e84b76",
      "metadata": {
        "id": "12fb7dc5-0233-4882-86fd-808875e84b76"
      },
      "source": [
        "<!-- Test Cell Boilerplate -->\n",
        "The cell below will test your solution for Exercise 3. The testing variables will be available for debugging under the following names in a dictionary format.\n",
        "- `input_vars` - Input variables for your solution.\n",
        "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
        "- `returned_output_vars` - Outputs returned by your solution.\n",
        "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61c49b7f-4f89-4716-8f8a-f30011011a7f",
      "metadata": {
        "id": "61c49b7f-4f89-4716-8f8a-f30011011a7f"
      },
      "outputs": [],
      "source": [
        "### test_cell_ex3\n",
        "exercise_start = time.time()\n",
        "from tester_fw.testers import Tester\n",
        "\n",
        "conf = {\n",
        "    'case_file':'tc_3',\n",
        "    'func': partition_journal, # replace this with the function defined above\n",
        "    'inputs':{ # input config dict. keys are parameter names\n",
        "        'df':{\n",
        "            'dtype':'pd.DataFrame', # data type of param.\n",
        "            'check_modified':True,\n",
        "        },\n",
        "        'audit_cols':{\n",
        "            'dtype':'list', # data type of param.\n",
        "            'check_modified':True,\n",
        "        },\n",
        "        'existing_journal':{\n",
        "            'dtype':'pd.DataFrame', # data type of param.\n",
        "            'check_modified':True,\n",
        "        }\n",
        "    },\n",
        "    'outputs':{\n",
        "        'historical_journal':{\n",
        "            'index':0,\n",
        "            'dtype':'pd.DataFrame',\n",
        "            'check_dtype': True,\n",
        "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
        "            'check_col_order': False, # Ignored if dtype is not df\n",
        "            'check_row_order': True, # Ignored if dtype is not df\n",
        "            'check_column_type': True, # Ignored if dtype is not df\n",
        "            'float_tolerance': 10 ** (-6)\n",
        "        },\n",
        "        'active_journal':{\n",
        "            'index':1,\n",
        "            'dtype':'pd.DataFrame',\n",
        "            'check_dtype': True,\n",
        "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
        "            'check_col_order': False, # Ignored if dtype is not df\n",
        "            'check_row_order': True, # Ignored if dtype is not df\n",
        "            'check_column_type': True, # Ignored if dtype is not df\n",
        "            'float_tolerance': 10 ** (-6)\n",
        "        }\n",
        "\n",
        "    }\n",
        "}\n",
        "tester = Tester(conf, key=b'6IRWMcPsVIAZqzDJnPgv_MfUZsxqo4Utjm2Favidv-A=', path='resources/')\n",
        "for _ in range(70):\n",
        "    try:\n",
        "        tester.run_test()\n",
        "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
        "    except:\n",
        "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
        "        raise\n",
        "\n",
        "### END HIDDEN TESTS\n",
        "exercise_end = time.time()\n",
        "print(f\"This test executed in {(pd.to_datetime(exercise_end, unit='s') - pd.to_datetime(exercise_start, unit='s')).seconds} seconds\")\n",
        "print('Passed! Please submit.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14a023b8-85fb-4104-b440-831a3d1c2ea0",
      "metadata": {
        "id": "14a023b8-85fb-4104-b440-831a3d1c2ea0"
      },
      "source": [
        "## Exercise 5 - (**3** Points):\n",
        "**Motivation** (don't dwell on this):  \n",
        "Our next task is to identify records which have changed and which records are unchanged. These are a subset of records having keys in both the business data and the active journal. We need to partition both the business data and journal data into two parts based on whether the data has changed.\n",
        "\n",
        "**Requirements**:  \n",
        "Define `compare_changes(compare_new_df, compare_old_df, audit_cols)`.\n",
        "\n",
        "The inputs are as follows:\n",
        "\n",
        "- `compare_new_df` - a DataFrame\n",
        "- `compare_old_df` - another DataFrame with the same columns/shape/indexing as `compare_new_df`\n",
        "- `audit_cols` - a list of column names which should not be used for comparison.\n",
        "\n",
        "You can assume that the rows `compare_new_df` and `compare_old_df` are sorted and indexed such that they can be compared directly.\n",
        "\n",
        "- Identify the columns in `compare_new_df` which are not in `audit_cols`. Let's call this `cols`.\n",
        "- Compare the values in `compare_new_df[cols]` with the values in `compare_old_df[cols]`.\n",
        "- Return these 3 new DataFrames:\n",
        "    - `unchanged` - All of the rows in `compare_new_df`  where **all** values are the same in the comparison.  \n",
        "    - `old_changed` - All of the rows in `compare_old_df` where there are **any** differences in the comparison.\n",
        "    - `new_changed` - All of the rows in `compare_new_df` where there are **any** differences in the comparison.\n",
        "\n",
        "It is possible that `compare_new_df` and `compare_old_df` are **both** empty DataFrames. If this is the case all 3 returned DataFrames would also be empty.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb1c051d-2c42-495f-8ae7-ffaf40935806",
      "metadata": {
        "id": "cb1c051d-2c42-495f-8ae7-ffaf40935806"
      },
      "outputs": [],
      "source": [
        "### Define demo inputs\n",
        "\n",
        "demo_compare_new_df_ex5 = pd.DataFrame([\n",
        "    {'some_column': 'new_val_0', 'key_column': 'changed_0', 'audit_column_1': None, 'audit_column_2': None},\n",
        "    {'some_column': 'new_val_1', 'key_column': 'changed_1', 'audit_column_1': None, 'audit_column_2': None},\n",
        "    {'some_column': 'same_val_0', 'key_column': 'unchanged_0', 'audit_column_1': None, 'audit_column_2': None},\n",
        "    {'some_column': 'same_val_1', 'key_column': 'unchanged_1', 'audit_column_1': None, 'audit_column_2': None},\n",
        "    {'some_column': 'new_val_2', 'key_column': 'changed_2', 'audit_column_1': None, 'audit_column_2': None},\n",
        "    {'some_column': 'same_val_2', 'key_column': 'unchanged_2', 'audit_column_1': None, 'audit_column_2': None}\n",
        "])\n",
        "\n",
        "demo_compare_old_df_ex5 = pd.DataFrame([\n",
        "    {'some_column': 'old_val_0', 'key_column': 'changed_0', 'audit_column_1': 'foo', 'audit_column_2': 'bar'},\n",
        "    {'some_column': 'old_val_1', 'key_column': 'changed_1', 'audit_column_1': 'foo', 'audit_column_2': 'bar'},\n",
        "    {'some_column': 'same_val_0', 'key_column': 'unchanged_0', 'audit_column_1': 'foo', 'audit_column_2': 'bar'},\n",
        "    {'some_column': 'same_val_1', 'key_column': 'unchanged_1', 'audit_column_1': 'foo', 'audit_column_2': 'bar'},\n",
        "    {'some_column': 'old_val_2', 'key_column': 'changed_2', 'audit_column_1': 'foo', 'audit_column_2': 'bar'},\n",
        "    {'some_column': 'same_val_2', 'key_column': 'unchanged_2', 'audit_column_1': 'foo', 'audit_column_2': 'bar'}\n",
        "])\n",
        "\n",
        "demo_audit_cols_ex5 = ['audit_column_1', 'audit_column_2']\n",
        "\n",
        "print('compare_new_df')\n",
        "print(demo_compare_new_df_ex5)\n",
        "print()\n",
        "print('compare_old_df')\n",
        "print(demo_compare_old_df_ex5)\n",
        "print()\n",
        "print('audit_cols')\n",
        "print(demo_audit_cols_ex5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f904128b-3d48-4743-b993-ec0cfaddbd73",
      "metadata": {
        "id": "f904128b-3d48-4743-b993-ec0cfaddbd73"
      },
      "outputs": [],
      "source": [
        "outline = '''\n",
        "output:\n",
        "    - (unchanged, old_changed, new_changed)\n",
        "        - data_type == DataFrames\n",
        "inputs:\n",
        "    - compare_new_df\n",
        "        - data_type == DataFrame\n",
        "    - compare_old_df\n",
        "        - data_type == DataFrame\n",
        "    - audit_cols\n",
        "        - data_type == list\n",
        "steps:\n",
        "    1. check to see if input dfs are empty\n",
        "        a. if empty, return 3 empty DataFrames with the right columns names\n",
        "    2. find cols that are not in audit_cols\n",
        "        a. get list of columns from compare_new_cols\n",
        "        b. if col in compare_new_cols not in audit_cols:\n",
        "            - add to new list, cols\n",
        "    3. create boolean mask - True when there is any difference between the two dfs[cols]\n",
        "    4. use different to partition the dfs\n",
        "    5. return (unchanged, old_changed, new_changed)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b8f5eb5-acca-4b8d-b501-daced35436ea",
      "metadata": {
        "id": "1b8f5eb5-acca-4b8d-b501-daced35436ea"
      },
      "outputs": [],
      "source": [
        "### Exercise 5 solution\n",
        "def compare_changes(compare_new_df, compare_old_df, audit_cols):\n",
        "    ###\n",
        "    ### YOUR CODE HERE\n",
        "    ###\n",
        "\n",
        "    # check for empty inputs\n",
        "    empty_df = pd.DataFrame()\n",
        "    if compare_new_df.shape[0] == compare_old_df.shape[0] == 0:\n",
        "        return (empty_df, empty_df, empty_df)\n",
        "\n",
        "    # find cols that are not in audit_cols\n",
        "    compare_new_cols = list(compare_new_df.columns)\n",
        "    cols = []\n",
        "    for i in compare_new_cols:\n",
        "        if i not in audit_cols:\n",
        "            cols.append(i)\n",
        "\n",
        "    # create boolean mask - True when there is any difference between the two frames, ignoring audit_cols\n",
        "    different = (compare_new_df[cols] != compare_old_df[cols])\n",
        "\n",
        "    # use different to partition the dfs\n",
        "    unchanged = compare_new_df.iloc[~different, :]\n",
        "    old_changed = compare_old_df.iloc[different, :]\n",
        "    new_changed = compare_new_df.iloc[different, :]\n",
        "\n",
        "    # return\n",
        "    return (unchanged, old_changed, new_changed)\n",
        "\n",
        "# Run demo of function\n",
        "(demo_unchanged_ex5,\n",
        "demo_old_changed_ex5,\n",
        "demo_new_changed_ex5) = compare_changes(demo_compare_new_df_ex5, demo_compare_old_df_ex5, demo_audit_cols_ex5)\n",
        "print('unchanged')\n",
        "print(demo_unchanged_ex5)\n",
        "print()\n",
        "print('old_changed')\n",
        "print(demo_old_changed_ex5)\n",
        "print()\n",
        "print('new_changed')\n",
        "print(demo_new_changed_ex5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90f1527a-d5b2-4d48-827c-eca7d7f17dbf",
      "metadata": {
        "id": "90f1527a-d5b2-4d48-827c-eca7d7f17dbf"
      },
      "outputs": [],
      "source": [
        "### test_cell_ex5\n",
        "exercise_start = time.time()\n",
        "from tester_fw.testers import Tester\n",
        "\n",
        "conf = {\n",
        "    'case_file':'tc_5',\n",
        "    'func': compare_changes, # replace this with the function defined above\n",
        "    'inputs':{ # input config dict. keys are parameter names\n",
        "        'compare_new_df':{\n",
        "            'dtype':'pd.DataFrame', # data type of param.\n",
        "            'check_modified':True,\n",
        "        },\n",
        "        'compare_old_df':{\n",
        "            'dtype':'pd.DataFrame', # data type of param.\n",
        "            'check_modified':True,\n",
        "        },\n",
        "        'audit_cols':{\n",
        "            'dtype':'list', # data type of param.\n",
        "            'check_modified':True,\n",
        "        }\n",
        "    },\n",
        "    'outputs':{\n",
        "        'unchanged':{\n",
        "            'index':0,\n",
        "            'dtype':'pd.DataFrame',\n",
        "            'check_dtype': True,\n",
        "            'check_col_dtypes': False, # Ignored if dtype is not df\n",
        "            'check_col_order': False, # Ignored if dtype is not df\n",
        "            'check_row_order': False, # Ignored if dtype is not df\n",
        "            'check_column_type': True, # Ignored if dtype is not df\n",
        "            'float_tolerance': 10 ** (-6)\n",
        "        },\n",
        "        'old_changed':{\n",
        "            'index':1,\n",
        "            'dtype':'pd.DataFrame',\n",
        "            'check_dtype': True,\n",
        "            'check_col_dtypes': False, # Ignored if dtype is not df\n",
        "            'check_col_order': False, # Ignored if dtype is not df\n",
        "            'check_row_order': False, # Ignored if dtype is not df\n",
        "            'check_column_type': True, # Ignored if dtype is not df\n",
        "            'float_tolerance': 10 ** (-6)\n",
        "        },\n",
        "        'new_changed':{\n",
        "            'index':2,\n",
        "            'dtype':'pd.DataFrame',\n",
        "            'check_dtype': True,\n",
        "            'check_col_dtypes': False, # Ignored if dtype is not df\n",
        "            'check_col_order': False, # Ignored if dtype is not df\n",
        "            'check_row_order': False, # Ignored if dtype is not df\n",
        "            'check_column_type': True, # Ignored if dtype is not df\n",
        "            'float_tolerance': 10 ** (-6)\n",
        "        }\n",
        "    }\n",
        "}\n",
        "tester = Tester(conf, key=b'6IRWMcPsVIAZqzDJnPgv_MfUZsxqo4Utjm2Favidv-A=', path='resources/')\n",
        "for _ in range(70):\n",
        "    try:\n",
        "        tester.run_test()\n",
        "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
        "    except:\n",
        "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
        "        raise\n",
        "\n",
        "exercise_end = time.time()\n",
        "print(f\"This test executed in {(pd.to_datetime(exercise_end, unit='s') - pd.to_datetime(exercise_start, unit='s')).seconds} seconds\")\n",
        "print('Passed! Please submit.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59cef587-5fff-47e4-8d2f-24a6b23990bc",
      "metadata": {
        "id": "59cef587-5fff-47e4-8d2f-24a6b23990bc"
      },
      "source": [
        "**Fin!** You’ve reached the end of this part. Don’t forget to restart and run all cells again to make sure it’s all working when run in sequence; and make sure your work passes the submission process. Good luck!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}