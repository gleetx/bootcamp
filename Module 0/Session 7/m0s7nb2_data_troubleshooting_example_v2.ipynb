{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Troubleshooting Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3b25f2b6cfc80b65",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## This sample notebook is to show you the testing paradigm that you will face on all of the exams.\n",
    "\n",
    "### The notebook contains Exercise 0 from Notebook 1, Part 2.\n",
    "\n",
    "#### What we are going to do is write code that purposely fails the exercise in multiple ways, to show you how to troubleshoot data errors on the exams.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# with open('resource/asnlib/publicdata/test_cases.pkl', 'rb') as fin:\n",
    "#     cases = pickle.load(fin)\n",
    "with open('test_cases.pkl', 'rb') as fin:\n",
    "    cases = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, let's solve the problem correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f3331b5182117a1f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Consider the following dataset of exam grades, organized as a 2-D table and stored in Python as a \"list of lists\" under the variable name, `grades`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9dc72b683a8858c7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "grades = [\n",
    "    # First line is descriptive header. Subsequent lines hold data\n",
    "    ['Student', 'Exam 1', 'Exam 2', 'Exam 3'],\n",
    "    ['Thorny', '100', '90', '80'],\n",
    "    ['Mac', '88', '99', '111'],\n",
    "    ['Farva', '45', '56', '67'],\n",
    "    ['Rabbit', '59', '61', '67'],\n",
    "    ['Ursula', '73', '79', '83'],\n",
    "    ['Foster', '89', '97', '101']\n",
    "]\n",
    "\n",
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-04082681e80572d5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Exercise 0** (`students_test`: 1 point). Complete the function `get_students` which takes a nested list `grades` as a parameter and reutrns a new list, `students`, which holds the names of the students as they from \"top to bottom\" in the table. \n",
    "- **Note**: the parameter `grades` will be similar to the table above in structure, but the data will be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "students",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_students(grades):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "    \n",
    "    # Sample solution code below\n",
    "    students = []\n",
    "\n",
    "    for i in grades:\n",
    "        if i[0] != 'Student':   #correct code\n",
    "            students.append(i[0])\n",
    "    return students\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The demo cell below should display `['Thorny', 'Mac', 'Farva', 'Rabbit', 'Ursula', 'Foster']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "students = get_students(grades)\n",
    "students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The test cell below will check your solution against several randomly generated test cases. If your solution does not pass the test (or if you're just curious), you can look at the variables used in the latest test run. They are automatically imported for you as part of the test.\n",
    "\n",
    "- `input_vars` - Dictionary containing all of the inputs to your function. Keys are the parameter names.\n",
    "- `original_input_vars` - Dictionary containing a copy of all the inputs to your function. This is useful for debugging failures related to your solution modifying the input. Keys are the parameter names.\n",
    "- `returned_output_vars` - Dictionary containing the outputs your function generated. If there are multiple outputs, the keys will match the names mentioned in the exercrise instructions.\n",
    "- `true_output_vars` - Dictionary containing the outputs your function **should have** generated. If there are multiple outputs, the keys will match the names mentioned in the exercrise instructions.\n",
    "\n",
    "All of the test cells in this notebook will use the same format, and you can expect a similar format on your exams as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "students_test",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# `students_test`: Test cell\n",
    "import nb_1_2_tester\n",
    "tester = nb_1_2_tester.Tester_1_2_0()\n",
    "for _ in range(20):\n",
    "    try:\n",
    "        tester.run_test(get_students)\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "print('Passed. Please submit!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will fail the exercise in multiple ways.\n",
    "\n",
    "## Recall the two tests that are performed. We will demonstrate failure of each test, and how to troubleshoot each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we will fail the test because we have modified the input in some way.\n",
    "\n",
    "We are going to deliberately write some code that obviously changes the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_students_modify_input(grades):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "#     print(grades)\n",
    "\n",
    "# this code modifies the input\n",
    "# uncomment to walk through\n",
    "#     grades.append(['This should not be here','50','60','70'])\n",
    "\n",
    "    # Sample solution code below\n",
    "    students = []\n",
    "\n",
    "    for i in grades:\n",
    "        if i[0] != 'Student':   #correct code\n",
    "            students.append(i[0])\n",
    "    return students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = get_students_modify_input(grades)\n",
    "students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test cell below will check your solution against several randomly generated test cases. If your solution does not pass the test (or if you're just curious), you can look at the variables used in the latest test run. They are automatically imported for you as part of the test.\n",
    "\n",
    "- `input_vars` - Dictionary containing all of the inputs to your function. Keys are the parameter names.\n",
    "- `original_input_vars` - Dictionary containing a copy of all the inputs to your function. This is useful for debugging failures related to your solution modifying the input. Keys are the parameter names.\n",
    "- `returned_output_vars` - Dictionary containing the outputs your function generated. If there are multiple outputs, the keys will match the names mentioned in the exercrise instructions.\n",
    "- `true_output_vars` - Dictionary containing the outputs your function **should have** generated. If there are multiple outputs, the keys will match the names mentioned in the exercrise instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `students_test`: Test cell\n",
    "import nb_1_2_tester\n",
    "tester = nb_1_2_tester.Tester_1_2_0()\n",
    "for _ in range(20):\n",
    "    try:\n",
    "        tester.run_test(get_students_modify_input)\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "print('Passed. Please submit!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So we have failed the exercise, and we can see from the AssertionError that we have modified the input variables in some way. \n",
    "\n",
    "What do we do now?\n",
    "\n",
    "#### As we said before, go back up to your code and find the line that has modified the input variables. There is no need to do any visual inspection at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will fail the test because our solution data is incorrect. Our first incorrect solution is because we have the wrong data type for our return variable.\n",
    "\n",
    "We are going to deliberately write some code that returns an incorrect solution with an incorrect data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the grades variable back to its original value\n",
    "grades = [\n",
    "    # First line is descriptive header. Subsequent lines hold data\n",
    "    ['Student', 'Exam 1', 'Exam 2', 'Exam 3'],\n",
    "    ['Thorny', '100', '90', '80'],\n",
    "    ['Mac', '88', '99', '111'],\n",
    "    ['Farva', '45', '56', '67'],\n",
    "    ['Rabbit', '59', '61', '67'],\n",
    "    ['Ursula', '73', '79', '83'],\n",
    "    ['Foster', '89', '97', '101']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_students_incorrect_data_type(grades):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "\n",
    "    # Sample solution code below\n",
    "    students = []\n",
    "\n",
    "    for i in grades:\n",
    "        if i[0] != 'Student':   #correct code\n",
    "            students.append(i[0])\n",
    "\n",
    "#     change the data type\n",
    "#     uncomment to show the error\n",
    "#     return set(students)\n",
    "\n",
    "    return students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo cell\n",
    "students = get_students_incorrect_data_type(grades)\n",
    "students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test cell below will check your solution against several randomly generated test cases. If your solution does not pass the test (or if you're just curious), you can look at the variables used in the latest test run. They are automatically imported for you as part of the test.\n",
    "\n",
    "- `input_vars` - Dictionary containing all of the inputs to your function. Keys are the parameter names.\n",
    "- `original_input_vars` - Dictionary containing a copy of all the inputs to your function. This is useful for debugging failures related to your solution modifying the input. Keys are the parameter names.\n",
    "- `returned_output_vars` - Dictionary containing the outputs your function generated. If there are multiple outputs, the keys will match the names mentioned in the exercrise instructions.\n",
    "- `true_output_vars` - Dictionary containing the outputs your function **should have** generated. If there are multiple outputs, the keys will match the names mentioned in the exercrise instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `students_test`: Test cell\n",
    "import nb_1_2_tester\n",
    "tester = nb_1_2_tester.Tester_1_2_0()\n",
    "for _ in range(20):\n",
    "    try:\n",
    "        tester.run_test(get_students_incorrect_data_type)\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "print('Passed. Please submit!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So we have failed the exercise, and we can see from the AssertionError that our returned output does not match the expected (solution) output. \n",
    "\n",
    "What do we do now?\n",
    "\n",
    "#### Now we have to figure out which of the three tests we failed (data type, length, actual data values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can do a visual inspection, if we think that we can find the differences this way.\n",
    "\n",
    "Note that we are using `display()` instead of `print()`. Why do you think we are doing this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ONLY UNCOMMENT IF YOU NEED IT!!!!\n",
    "# # BEWARE THAT THIS COULD GENERATE VOLUMINOUS OUTPUT!!!!!\n",
    "\n",
    "# uncomment for visual inspection\n",
    "print('returned_output_vars')\n",
    "display(returned_output_vars)\n",
    "print('\\ntrue_output_vars')\n",
    "display(true_output_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have not covered dictionaries in the bootcamp yet, but note that the `test case variables` are dictionaries.\n",
    "\n",
    "1. The key of each dictionary is the name of the returned variable. In this case, the key is `'students'`. If there are multiple returned variables, there will be a separate key for each.\n",
    "\n",
    "2. The value of each dictionary is the actual variable values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# addressing the keys and values\n",
    "print(\"Keys\")\n",
    "display(true_output_vars.keys())\n",
    "\n",
    "print('\\nValues')\n",
    "display(true_output_vars['students'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we are able to find the differences by visual inspection, great. Now go back up the code and figure out what we need to change.\n",
    "\n",
    "#### But what if we are not able to see the difference(s) by visual inspection? This is VERY COMMON.\n",
    "\n",
    "So let's programmatically find out the differences. \n",
    "\n",
    "For whichever difference is the issue, you must then go back up to your code and work through where you have introduced the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First test, do we have the same data types?\n",
    "for k_t,v_t in true_output_vars.items():\n",
    "    \n",
    "    for k_r,v_r in returned_output_vars.items():\n",
    "\n",
    "#     # check for datatype (list,dict,set)\n",
    "        if type(v_t) == type(v_r):\n",
    "            print('Output data types match\\n')\n",
    "        else:\n",
    "            print('Output data types do not match')\n",
    "            print('true_output_vars data type: ',type(v_t))\n",
    "            print('returned_output_vars data type: ',type(v_r),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our next incorrect solution is because the length of our returned output variable is different from the length of the true output variable.\n",
    "\n",
    "We are going to deliberately write some code that returns an incorrect solution with an incorrect length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_students_incorrect_length(grades):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "\n",
    "    # Sample solution code below\n",
    "    students = []\n",
    "\n",
    "    for i in grades:\n",
    "        if i[0] != 'Student':   #correct code\n",
    "            students.append(i[0])\n",
    "            \n",
    "#         changes the length of the returned data\n",
    "#         incorrect code, uncomment the next two line to walk through\n",
    "#         elif i[0] == 'Student':   \n",
    "#             students.append(i[0])\n",
    "\n",
    "    return students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo cell\n",
    "students = get_students_incorrect_length(grades)\n",
    "students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test cell below will check your solution against several randomly generated test cases. If your solution does not pass the test (or if you're just curious), you can look at the variables used in the latest test run. They are automatically imported for you as part of the test.\n",
    "\n",
    "- `input_vars` - Dictionary containing all of the inputs to your function. Keys are the parameter names.\n",
    "- `original_input_vars` - Dictionary containing a copy of all the inputs to your function. This is useful for debugging failures related to your solution modifying the input. Keys are the parameter names.\n",
    "- `returned_output_vars` - Dictionary containing the outputs your function generated. If there are multiple outputs, the keys will match the names mentioned in the exercrise instructions.\n",
    "- `true_output_vars` - Dictionary containing the outputs your function **should have** generated. If there are multiple outputs, the keys will match the names mentioned in the exercrise instructions.\n",
    "\n",
    "All of the test cells in this notebook will use the same format, and you can expect a similar format on your exams as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `students_test`: Test cell\n",
    "import nb_1_2_tester\n",
    "tester = nb_1_2_tester.Tester_1_2_0()\n",
    "for _ in range(20):\n",
    "    try:\n",
    "        tester.run_test(get_students_incorrect_length)\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "print('Passed. Please submit!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second test, do we have the same lengths?\n",
    "for k_t,v_t in true_output_vars.items():\n",
    "    \n",
    "    for k_r,v_r in returned_output_vars.items():\n",
    "\n",
    "#     # check for the length of the solution (lists,dict,set)\n",
    "        if len(v_t) == len(v_r):\n",
    "            print('Output lengths match\\n')\n",
    "        elif len(v_t) > len(v_r):\n",
    "            print('true_output_vars is longer than returned_output_vars.')\n",
    "            print('Your solution does not have enough data in it.')\n",
    "            print('true_output_vars length:',len(v_t))\n",
    "            print('returned_output_vars length:',len(v_r))\n",
    "        else:\n",
    "            print('returned_output_vars is longer than true_output_vars.')\n",
    "            print('Your solution has too much data in it.')\n",
    "            print('true_output_vars length:',len(v_t))\n",
    "            print('returned_output_vars length:',len(v_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When there is length difference your output variables, the most likely reason is that you failed to correctly deal with one of the exercise requirements. You have done one of the following:\n",
    "\n",
    "    1. Included a value that should have been excluded (your output is longer than what it should be).\n",
    "\n",
    "    2. Excluded a value that should have been included (your output is shorter than what it should be).\n",
    "\n",
    "#### At this point, our method is to output/display the two variables and visually compare them, to  find the missing/extra value.\n",
    "\n",
    "\n",
    "#### Once we know what the extra/missing value is, we must go back to our code and compare it with each of the include/exclude requirements, to see which requirement we did not do correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we included the key `'Student'` in our output. This key is not the name of an actual student, so it should not have been included. So our output is longer than what it should have been. \n",
    "\n",
    "We can go back to our code, find where we have included this, and remove that code.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our final incorrect solution is because the actual data in our returned output variable is different from the data of the true output variable.\n",
    "\n",
    "We are going to deliberately write some code that returns an incorrect solution with incorrect data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So what if the first two checks pass? This generally means that your code is computing something incorrectly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the grades variable back to its original value\n",
    "grades = [\n",
    "    # First line is descriptive header. Subsequent lines hold data\n",
    "    ['Student', 'Exam 1', 'Exam 2', 'Exam 3'],\n",
    "    ['Thorny', '100', '90', '80'],\n",
    "    ['Mac', '88', '99', '111'],\n",
    "    ['Farva', '45', '56', '67'],\n",
    "    ['Rabbit', '59', '61', '67'],\n",
    "    ['Ursula', '73', '79', '83'],\n",
    "    ['Foster', '89', '97', '101']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_students_incorrect_data(grades):\n",
    "    ###\n",
    "    ### YOUR CODE HERE\n",
    "    ###\n",
    "\n",
    "    import copy\n",
    "#     https://www.geeksforgeeks.org/copy-python-deep-copy-shallow-copy/\n",
    "    grades_copy = copy.deepcopy(grades)   #why do this? this is a deep copy\n",
    "\n",
    "    # Sample solution code below\n",
    "    students = []\n",
    "\n",
    "    for i in grades_copy:\n",
    "        if i[0] != 'Student':   #correct code\n",
    "            \n",
    "#             change the data so that it is different from the solution\n",
    "#             incorrect code, uncomment the next line to walk through\n",
    "#             i[0] += \"aaa\"\n",
    "            \n",
    "            students.append(i[0])\n",
    "\n",
    "    return students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demo cell\n",
    "students = get_students_incorrect_data(grades)\n",
    "students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test cell below will check your solution against several randomly generated test cases. If your solution does not pass the test (or if you're just curious), you can look at the variables used in the latest test run. They are automatically imported for you as part of the test.\n",
    "\n",
    "- `input_vars` - Dictionary containing all of the inputs to your function. Keys are the parameter names.\n",
    "- `original_input_vars` - Dictionary containing a copy of all the inputs to your function. This is useful for debugging failures related to your solution modifying the input. Keys are the parameter names.\n",
    "- `returned_output_vars` - Dictionary containing the outputs your function generated. If there are multiple outputs, the keys will match the names mentioned in the exercrise instructions.\n",
    "- `true_output_vars` - Dictionary containing the outputs your function **should have** generated. If there are multiple outputs, the keys will match the names mentioned in the exercrise instructions.\n",
    "\n",
    "All of the test cells in this notebook will use the same format, and you can expect a similar format on your exams as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `students_test`: Test cell\n",
    "import nb_1_2_tester\n",
    "tester = nb_1_2_tester.Tester_1_2_0()\n",
    "for _ in range(20):\n",
    "    try:\n",
    "        tester.run_test(get_students_incorrect_data)\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "print('Passed. Please submit!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So how do we deal with this third test scenario? We have several options, but none of them are \"easy fixes\".\n",
    "\n",
    "### Ultimately, you are going to have to go back to your code and find/correct what you have written wrong.\n",
    "\n",
    "1. Visually inspect the `test case variables` and find the difference(s). Then go back to the line(s) of code that produced the difference(s).\n",
    "\n",
    "2. Go back into your code directly and walk through each step, comparing it the requirement/step that it executes, to see if you can find the error. \n",
    "\n",
    "    ***Some examples include:*** \n",
    "\n",
    "\n",
    "    1. You have written a math code equation wrong.\n",
    "\n",
    "    2. You are incorrectly assigning a value.\n",
    "\n",
    "    3. You have some string manipulation wrong.\n",
    "\n",
    "    4. You have a logic error.\n",
    "\n",
    "    5. You have sorted incorrectly (or failed to sort when you should have).\n",
    "\n",
    "    6. You have incorrectly rounded numeric data (or failed to round when you should have)\n",
    "    \n",
    "3. Write a code loop that compares each element individually and outputs an error message when they are not the same. \n",
    "\n",
    "    To do this, you must write a loop for the data type of your returned variable. \n",
    "    \n",
    "    This is a (potentially) complex and time-consuming operation, and it requires a solid understanding of the data types.\n",
    "    \n",
    "    and as such, we are not going to show this technique. \n",
    "    \n",
    "    With unlimited exam time, we might teach this methodology, but for students with limited programming backgrounds, at this point in the course, we believe that this is not a good use of time and resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment for visual inspection\n",
    "print('returned_output_vars\\n')\n",
    "print(returned_output_vars)\n",
    "print('\\ntrue_output_vars\\n')\n",
    "print(true_output_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another means of printing out the results\n",
    "for i in returned_output_vars:\n",
    "    print(returned_output_vars.get(i))\n",
    "    print(true_output_vars.get(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One final note, concerning the demo cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The demo cells are designed to give you some sample data, to help you to get your code up and running. You will see these for every exercise on all of the exams.\n",
    "\n",
    "## Note that I can pass the demo cell and still fail the test cell!!!\n",
    "\n",
    "This will be ***ONE OF THE BIGGEST PROBLEMS*** for students on the exams.\n",
    "\n",
    "Students think that, because they passed the DEMO CELL, it means that they WILL ALSO pass the TEST CELL.\n",
    "\n",
    "This IS NOT the case, as the DEMO CELL is designed to give you some SAMPLE DATA, to help you get your code up and running."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The DEMO CELL IS NOT a full test of your code, and you can easily pass the DEMO CELL and FAIL the TEST CELL!!! \n",
    "\n",
    "## The TEST CELL is a FULL TEST of your code, and it is much more extensive than the DEMO CELL.\n",
    "\n",
    "## So be aware that you can pass the DEMO CELL and still fail the TEST CELL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***ON EVERY EXAM***, there will be ***AT LEAST 20 Piazza posts*** from students whose code passes the demo cell and fails the test cell. They will post that there is a BUG in the exam because of this, when in fact, their code is incorrect.\n",
    "\n",
    "Please be aware of this difference between the demo and test cells.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are your questions concerning data troubleshooting using the `test case variables`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
